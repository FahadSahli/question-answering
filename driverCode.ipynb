{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"driverCode.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOMZnJ5pphKXrqrp4SdcB4q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Q1YiBx_zfieo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594940215225,"user_tz":-180,"elapsed":946,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"ec083dac-f3c2-4b7c-8833-db42c1c39961"},"source":["#connection to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a9ay6qQkgsTF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594939989736,"user_tz":-180,"elapsed":5943,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"16e23608-da5f-4093-98ef-a62138e50d13"},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B9sJJ3lXhDBM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591998710689,"user_tz":-180,"elapsed":2554,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"5eb33610-9429-483a-fef2-8ea485c6b3b9"},"source":["! cd /content/drive/My\\ Drive/192/Thesis/models/stand_alone/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: cd: too many arguments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eT2am4vQfqpc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594969971639,"user_tz":-180,"elapsed":29676080,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"3c64713e-bfbe-41db-efa0-8074b76fcf42"},"source":["!python3 /content/drive/My\\ Drive/192/Thesis/models/stand_alone/HAN.py --training True --testing False --data /content/drive/My\\ Drive/192/Thesis/ --embedding_file /content/drive/My\\ Drive/192/Thesis/embeddings/glove.6B.200d.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Trained samples in this epoch : 80896\n","Step : 1263/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4343\n","Trained samples in this epoch : 80960\n","Step : 1264/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 81024\n","Step : 1265/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 81088\n","Step : 1266/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81152\n","Step : 1267/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81216\n","Step : 1268/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81280\n","Step : 1269/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 81344\n","Step : 1270/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 81408\n","Step : 1271/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81472\n","Step : 1272/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 81536\n","Step : 1273/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 81600\n","Step : 1274/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 81664\n","Step : 1275/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 81728\n","Step : 1276/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 81792\n","Step : 1277/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81856\n","Step : 1278/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81920\n","Step : 1279/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 81984\n","Step : 1280/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 82048\n","Step : 1281/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 82112\n","Step : 1282/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 82176\n","Step : 1283/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 82240\n","Step : 1284/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 82304\n","Step : 1285/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82368\n","Step : 1286/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82432\n","Step : 1287/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82496\n","Step : 1288/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82560\n","Step : 1289/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82624\n","Step : 1290/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82688\n","Step : 1291/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 82752\n","Step : 1292/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 82816\n","Step : 1293/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 82880\n","Step : 1294/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 82944\n","Step : 1295/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4344\n","Trained samples in this epoch : 83008\n","Step : 1296/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 83072\n","Step : 1297/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4345\n","Trained samples in this epoch : 83136\n","Step : 1298/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 83200\n","Step : 1299/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 83264\n","Step : 1300/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 83328\n","Step : 1301/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 83392\n","Step : 1302/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 83456\n","Step : 1303/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83520\n","Step : 1304/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83584\n","Step : 1305/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83648\n","Step : 1306/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Val acc : 0.4093\n","Val Loss : 1.6154\n","Save model to ./machine_reading-val_acc-0.4093-val_loss-1.6154.model-6400.\n","Trained samples in this epoch : 83712\n","Step : 1307/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83776\n","Step : 1308/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83840\n","Step : 1309/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83904\n","Step : 1310/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 83968\n","Step : 1311/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4346\n","Trained samples in this epoch : 84032\n","Step : 1312/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84096\n","Step : 1313/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84160\n","Step : 1314/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84224\n","Step : 1315/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84288\n","Step : 1316/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84352\n","Step : 1317/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 84416\n","Step : 1318/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 84480\n","Step : 1319/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 84544\n","Step : 1320/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 84608\n","Step : 1321/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 84672\n","Step : 1322/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 84736\n","Step : 1323/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 84800\n","Step : 1324/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 84864\n","Step : 1325/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 84928\n","Step : 1326/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 84992\n","Step : 1327/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85056\n","Step : 1328/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85120\n","Step : 1329/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85184\n","Step : 1330/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85248\n","Step : 1331/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85312\n","Step : 1332/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85376\n","Step : 1333/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85440\n","Step : 1334/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85504\n","Step : 1335/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85568\n","Step : 1336/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85632\n","Step : 1337/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85696\n","Step : 1338/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85760\n","Step : 1339/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85824\n","Step : 1340/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85888\n","Step : 1341/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 85952\n","Step : 1342/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 86016\n","Step : 1343/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 86080\n","Step : 1344/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 86144\n","Step : 1345/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 86208\n","Step : 1346/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86272\n","Step : 1347/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 86336\n","Step : 1348/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 86400\n","Step : 1349/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 86464\n","Step : 1350/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 86528\n","Step : 1351/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86592\n","Step : 1352/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86656\n","Step : 1353/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86720\n","Step : 1354/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86784\n","Step : 1355/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86848\n","Step : 1356/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 86912\n","Step : 1357/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 86976\n","Step : 1358/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87040\n","Step : 1359/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87104\n","Step : 1360/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 87168\n","Step : 1361/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 87232\n","Step : 1362/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87296\n","Step : 1363/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87360\n","Step : 1364/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87424\n","Step : 1365/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 87488\n","Step : 1366/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 87552\n","Step : 1367/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 87616\n","Step : 1368/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 87680\n","Step : 1369/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87744\n","Step : 1370/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87808\n","Step : 1371/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87872\n","Step : 1372/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 87936\n","Step : 1373/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 88000\n","Step : 1374/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 88064\n","Step : 1375/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 88128\n","Step : 1376/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88192\n","Step : 1377/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88256\n","Step : 1378/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88320\n","Step : 1379/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 88384\n","Step : 1380/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88448\n","Step : 1381/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88512\n","Step : 1382/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88576\n","Step : 1383/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88640\n","Step : 1384/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88704\n","Step : 1385/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88768\n","Step : 1386/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88832\n","Step : 1387/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88896\n","Step : 1388/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 88960\n","Step : 1389/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 89024\n","Step : 1390/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89088\n","Step : 1391/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 89152\n","Step : 1392/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89216\n","Step : 1393/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89280\n","Step : 1394/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 89344\n","Step : 1395/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89408\n","Step : 1396/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89472\n","Step : 1397/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89536\n","Step : 1398/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 89600\n","Step : 1399/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 89664\n","Step : 1400/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 89728\n","Step : 1401/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 89792\n","Step : 1402/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 89856\n","Step : 1403/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 89920\n","Step : 1404/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 89984\n","Step : 1405/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90048\n","Step : 1406/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90112\n","Step : 1407/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90176\n","Step : 1408/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90240\n","Step : 1409/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90304\n","Step : 1410/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90368\n","Step : 1411/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90432\n","Step : 1412/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90496\n","Step : 1413/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 90560\n","Step : 1414/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 90624\n","Step : 1415/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 90688\n","Step : 1416/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 90752\n","Step : 1417/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 90816\n","Step : 1418/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 90880\n","Step : 1419/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 90944\n","Step : 1420/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91008\n","Step : 1421/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91072\n","Step : 1422/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4347\n","Trained samples in this epoch : 91136\n","Step : 1423/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91200\n","Step : 1424/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91264\n","Step : 1425/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91328\n","Step : 1426/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91392\n","Step : 1427/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91456\n","Step : 1428/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91520\n","Step : 1429/1698.\n","Loss : 1.5260.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91584\n","Step : 1430/1698.\n","Loss : 1.5260.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91648\n","Step : 1431/1698.\n","Loss : 1.5260.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91712\n","Step : 1432/1698.\n","Loss : 1.5261.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 91776\n","Step : 1433/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 91840\n","Step : 1434/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 91904\n","Step : 1435/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 91968\n","Step : 1436/1698.\n","Loss : 1.5259.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 92032\n","Step : 1437/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 92096\n","Step : 1438/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 92160\n","Step : 1439/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 92224\n","Step : 1440/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 92288\n","Step : 1441/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 92352\n","Step : 1442/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 92416\n","Step : 1443/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 92480\n","Step : 1444/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92544\n","Step : 1445/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92608\n","Step : 1446/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92672\n","Step : 1447/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92736\n","Step : 1448/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92800\n","Step : 1449/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92864\n","Step : 1450/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92928\n","Step : 1451/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 92992\n","Step : 1452/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 93056\n","Step : 1453/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 93120\n","Step : 1454/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 93184\n","Step : 1455/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93248\n","Step : 1456/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93312\n","Step : 1457/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93376\n","Step : 1458/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93440\n","Step : 1459/1698.\n","Loss : 1.5258.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93504\n","Step : 1460/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 93568\n","Step : 1461/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93632\n","Step : 1462/1698.\n","Loss : 1.5257.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93696\n","Step : 1463/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93760\n","Step : 1464/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93824\n","Step : 1465/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 93888\n","Step : 1466/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 93952\n","Step : 1467/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 94016\n","Step : 1468/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 94080\n","Step : 1469/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 94144\n","Step : 1470/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94208\n","Step : 1471/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94272\n","Step : 1472/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94336\n","Step : 1473/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94400\n","Step : 1474/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94464\n","Step : 1475/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94528\n","Step : 1476/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94592\n","Step : 1477/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94656\n","Step : 1478/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4354\n","Trained samples in this epoch : 94720\n","Step : 1479/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94784\n","Step : 1480/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94848\n","Step : 1481/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94912\n","Step : 1482/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 94976\n","Step : 1483/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95040\n","Step : 1484/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95104\n","Step : 1485/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95168\n","Step : 1486/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95232\n","Step : 1487/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95296\n","Step : 1488/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95360\n","Step : 1489/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95424\n","Step : 1490/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95488\n","Step : 1491/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95552\n","Step : 1492/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95616\n","Step : 1493/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95680\n","Step : 1494/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 95744\n","Step : 1495/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 95808\n","Step : 1496/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 95872\n","Step : 1497/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 95936\n","Step : 1498/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96000\n","Step : 1499/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96064\n","Step : 1500/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96128\n","Step : 1501/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96192\n","Step : 1502/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96256\n","Step : 1503/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96320\n","Step : 1504/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 96384\n","Step : 1505/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96448\n","Step : 1506/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Val acc : 0.4062\n","Val Loss : 1.6114\n","Save model to ./machine_reading-val_acc-0.4062-val_loss-1.6114.model-6600.\n","Trained samples in this epoch : 96512\n","Step : 1507/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96576\n","Step : 1508/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 96640\n","Step : 1509/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 96704\n","Step : 1510/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 96768\n","Step : 1511/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 96832\n","Step : 1512/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 96896\n","Step : 1513/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 96960\n","Step : 1514/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97024\n","Step : 1515/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97088\n","Step : 1516/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97152\n","Step : 1517/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97216\n","Step : 1518/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97280\n","Step : 1519/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97344\n","Step : 1520/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97408\n","Step : 1521/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 97472\n","Step : 1522/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97536\n","Step : 1523/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97600\n","Step : 1524/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97664\n","Step : 1525/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 97728\n","Step : 1526/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97792\n","Step : 1527/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 97856\n","Step : 1528/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 97920\n","Step : 1529/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 97984\n","Step : 1530/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98048\n","Step : 1531/1698.\n","Loss : 1.5256.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98112\n","Step : 1532/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98176\n","Step : 1533/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98240\n","Step : 1534/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98304\n","Step : 1535/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98368\n","Step : 1536/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98432\n","Step : 1537/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 98496\n","Step : 1538/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98560\n","Step : 1539/1698.\n","Loss : 1.5255.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98624\n","Step : 1540/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98688\n","Step : 1541/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98752\n","Step : 1542/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 98816\n","Step : 1543/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 98880\n","Step : 1544/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 98944\n","Step : 1545/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 99008\n","Step : 1546/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 99072\n","Step : 1547/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 99136\n","Step : 1548/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 99200\n","Step : 1549/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 99264\n","Step : 1550/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 99328\n","Step : 1551/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 99392\n","Step : 1552/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 99456\n","Step : 1553/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99520\n","Step : 1554/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99584\n","Step : 1555/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99648\n","Step : 1556/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 99712\n","Step : 1557/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99776\n","Step : 1558/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 99840\n","Step : 1559/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99904\n","Step : 1560/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 99968\n","Step : 1561/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 100032\n","Step : 1562/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 100096\n","Step : 1563/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 100160\n","Step : 1564/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 100224\n","Step : 1565/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100288\n","Step : 1566/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100352\n","Step : 1567/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100416\n","Step : 1568/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100480\n","Step : 1569/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100544\n","Step : 1570/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100608\n","Step : 1571/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100672\n","Step : 1572/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100736\n","Step : 1573/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100800\n","Step : 1574/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100864\n","Step : 1575/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100928\n","Step : 1576/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 100992\n","Step : 1577/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 101056\n","Step : 1578/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 101120\n","Step : 1579/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 101184\n","Step : 1580/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 101248\n","Step : 1581/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 101312\n","Step : 1582/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 101376\n","Step : 1583/1698.\n","Loss : 1.5253.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 101440\n","Step : 1584/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 101504\n","Step : 1585/1698.\n","Loss : 1.5254.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 101568\n","Step : 1586/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 101632\n","Step : 1587/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 101696\n","Step : 1588/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 101760\n","Step : 1589/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 101824\n","Step : 1590/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 101888\n","Step : 1591/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 101952\n","Step : 1592/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102016\n","Step : 1593/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102080\n","Step : 1594/1698.\n","Loss : 1.5252.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102144\n","Step : 1595/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102208\n","Step : 1596/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102272\n","Step : 1597/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102336\n","Step : 1598/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102400\n","Step : 1599/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 102464\n","Step : 1600/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102528\n","Step : 1601/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 102592\n","Step : 1602/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102656\n","Step : 1603/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102720\n","Step : 1604/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102784\n","Step : 1605/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102848\n","Step : 1606/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102912\n","Step : 1607/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 102976\n","Step : 1608/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 103040\n","Step : 1609/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103104\n","Step : 1610/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103168\n","Step : 1611/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103232\n","Step : 1612/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103296\n","Step : 1613/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103360\n","Step : 1614/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103424\n","Step : 1615/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 103488\n","Step : 1616/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103552\n","Step : 1617/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103616\n","Step : 1618/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103680\n","Step : 1619/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103744\n","Step : 1620/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103808\n","Step : 1621/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103872\n","Step : 1622/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 103936\n","Step : 1623/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 104000\n","Step : 1624/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 104064\n","Step : 1625/1698.\n","Loss : 1.5242.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 104128\n","Step : 1626/1698.\n","Loss : 1.5241.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 104192\n","Step : 1627/1698.\n","Loss : 1.5243.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 104256\n","Step : 1628/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 104320\n","Step : 1629/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 104384\n","Step : 1630/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 104448\n","Step : 1631/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 104512\n","Step : 1632/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 104576\n","Step : 1633/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 104640\n","Step : 1634/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 104704\n","Step : 1635/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 104768\n","Step : 1636/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 104832\n","Step : 1637/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 104896\n","Step : 1638/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 104960\n","Step : 1639/1698.\n","Loss : 1.5251.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 105024\n","Step : 1640/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105088\n","Step : 1641/1698.\n","Loss : 1.5250.\n","Accuracy : 0.4348\n","Trained samples in this epoch : 105152\n","Step : 1642/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105216\n","Step : 1643/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105280\n","Step : 1644/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105344\n","Step : 1645/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105408\n","Step : 1646/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105472\n","Step : 1647/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4349\n","Trained samples in this epoch : 105536\n","Step : 1648/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105600\n","Step : 1649/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105664\n","Step : 1650/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105728\n","Step : 1651/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105792\n","Step : 1652/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105856\n","Step : 1653/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105920\n","Step : 1654/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 105984\n","Step : 1655/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106048\n","Step : 1656/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106112\n","Step : 1657/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106176\n","Step : 1658/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106240\n","Step : 1659/1698.\n","Loss : 1.5249.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106304\n","Step : 1660/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106368\n","Step : 1661/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106432\n","Step : 1662/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 106496\n","Step : 1663/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106560\n","Step : 1664/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","Trained samples in this epoch : 106624\n","Step : 1665/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 106688\n","Step : 1666/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 106752\n","Step : 1667/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 106816\n","Step : 1668/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 106880\n","Step : 1669/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 106944\n","Step : 1670/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107008\n","Step : 1671/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107072\n","Step : 1672/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107136\n","Step : 1673/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107200\n","Step : 1674/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4353\n","Trained samples in this epoch : 107264\n","Step : 1675/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107328\n","Step : 1676/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107392\n","Step : 1677/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107456\n","Step : 1678/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107520\n","Step : 1679/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107584\n","Step : 1680/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 107648\n","Step : 1681/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 107712\n","Step : 1682/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107776\n","Step : 1683/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107840\n","Step : 1684/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 107904\n","Step : 1685/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 107968\n","Step : 1686/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108032\n","Step : 1687/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 108096\n","Step : 1688/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108160\n","Step : 1689/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108224\n","Step : 1690/1698.\n","Loss : 1.5247.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108288\n","Step : 1691/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108352\n","Step : 1692/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 108416\n","Step : 1693/1698.\n","Loss : 1.5245.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108480\n","Step : 1694/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 108544\n","Step : 1695/1698.\n","Loss : 1.5244.\n","Accuracy : 0.4352\n","Trained samples in this epoch : 108608\n","Step : 1696/1698.\n","Loss : 1.5246.\n","Accuracy : 0.4351\n","Trained samples in this epoch : 108672\n","Step : 1697/1698.\n","Loss : 1.5248.\n","Accuracy : 0.4350\n","--------Epoch : 5\n","Trained samples in this epoch : 64\n","Step : 0/1698.\n","Loss : 1.6636.\n","Accuracy : 0.4062\n","Trained samples in this epoch : 128\n","Step : 1/1698.\n","Loss : 1.5374.\n","Accuracy : 0.4688\n","Trained samples in this epoch : 192\n","Step : 2/1698.\n","Loss : 1.5204.\n","Accuracy : 0.4740\n","Trained samples in this epoch : 256\n","Step : 3/1698.\n","Loss : 1.4663.\n","Accuracy : 0.4961\n","Trained samples in this epoch : 320\n","Step : 4/1698.\n","Loss : 1.4490.\n","Accuracy : 0.4750\n","Trained samples in this epoch : 384\n","Step : 5/1698.\n","Loss : 1.4280.\n","Accuracy : 0.4792\n","Trained samples in this epoch : 448\n","Step : 6/1698.\n","Loss : 1.4374.\n","Accuracy : 0.4732\n","Trained samples in this epoch : 512\n","Step : 7/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4590\n","Trained samples in this epoch : 576\n","Step : 8/1698.\n","Loss : 1.4396.\n","Accuracy : 0.4583\n","Val acc : 0.4027\n","Val Loss : 1.6160\n","Lose_time/Patience : 1/5 .\n","Trained samples in this epoch : 640\n","Step : 9/1698.\n","Loss : 1.4454.\n","Accuracy : 0.4609\n","Trained samples in this epoch : 704\n","Step : 10/1698.\n","Loss : 1.4448.\n","Accuracy : 0.4616\n","Trained samples in this epoch : 768\n","Step : 11/1698.\n","Loss : 1.4381.\n","Accuracy : 0.4622\n","Trained samples in this epoch : 832\n","Step : 12/1698.\n","Loss : 1.4519.\n","Accuracy : 0.4603\n","Trained samples in this epoch : 896\n","Step : 13/1698.\n","Loss : 1.4640.\n","Accuracy : 0.4609\n","Trained samples in this epoch : 960\n","Step : 14/1698.\n","Loss : 1.4715.\n","Accuracy : 0.4573\n","Trained samples in this epoch : 1024\n","Step : 15/1698.\n","Loss : 1.4681.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 1088\n","Step : 16/1698.\n","Loss : 1.4680.\n","Accuracy : 0.4476\n","Trained samples in this epoch : 1152\n","Step : 17/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4479\n","Trained samples in this epoch : 1216\n","Step : 18/1698.\n","Loss : 1.4625.\n","Accuracy : 0.4465\n","Trained samples in this epoch : 1280\n","Step : 19/1698.\n","Loss : 1.4665.\n","Accuracy : 0.4469\n","Trained samples in this epoch : 1344\n","Step : 20/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4479\n","Trained samples in this epoch : 1408\n","Step : 21/1698.\n","Loss : 1.4672.\n","Accuracy : 0.4474\n","Trained samples in this epoch : 1472\n","Step : 22/1698.\n","Loss : 1.4619.\n","Accuracy : 0.4511\n","Trained samples in this epoch : 1536\n","Step : 23/1698.\n","Loss : 1.4560.\n","Accuracy : 0.4525\n","Trained samples in this epoch : 1600\n","Step : 24/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4525\n","Trained samples in this epoch : 1664\n","Step : 25/1698.\n","Loss : 1.4477.\n","Accuracy : 0.4579\n","Trained samples in this epoch : 1728\n","Step : 26/1698.\n","Loss : 1.4451.\n","Accuracy : 0.4601\n","Trained samples in this epoch : 1792\n","Step : 27/1698.\n","Loss : 1.4481.\n","Accuracy : 0.4598\n","Trained samples in this epoch : 1856\n","Step : 28/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4574\n","Trained samples in this epoch : 1920\n","Step : 29/1698.\n","Loss : 1.4460.\n","Accuracy : 0.4578\n","Trained samples in this epoch : 1984\n","Step : 30/1698.\n","Loss : 1.4485.\n","Accuracy : 0.4582\n","Trained samples in this epoch : 2048\n","Step : 31/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 2112\n","Step : 32/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4564\n","Trained samples in this epoch : 2176\n","Step : 33/1698.\n","Loss : 1.4562.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 2240\n","Step : 34/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4580\n","Trained samples in this epoch : 2304\n","Step : 35/1698.\n","Loss : 1.4520.\n","Accuracy : 0.4596\n","Trained samples in this epoch : 2368\n","Step : 36/1698.\n","Loss : 1.4568.\n","Accuracy : 0.4595\n","Trained samples in this epoch : 2432\n","Step : 37/1698.\n","Loss : 1.4555.\n","Accuracy : 0.4597\n","Trained samples in this epoch : 2496\n","Step : 38/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4595\n","Trained samples in this epoch : 2560\n","Step : 39/1698.\n","Loss : 1.4479.\n","Accuracy : 0.4637\n","Trained samples in this epoch : 2624\n","Step : 40/1698.\n","Loss : 1.4469.\n","Accuracy : 0.4619\n","Trained samples in this epoch : 2688\n","Step : 41/1698.\n","Loss : 1.4492.\n","Accuracy : 0.4635\n","Trained samples in this epoch : 2752\n","Step : 42/1698.\n","Loss : 1.4463.\n","Accuracy : 0.4640\n","Trained samples in this epoch : 2816\n","Step : 43/1698.\n","Loss : 1.4486.\n","Accuracy : 0.4609\n","Trained samples in this epoch : 2880\n","Step : 44/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4590\n","Trained samples in this epoch : 2944\n","Step : 45/1698.\n","Loss : 1.4454.\n","Accuracy : 0.4616\n","Trained samples in this epoch : 3008\n","Step : 46/1698.\n","Loss : 1.4408.\n","Accuracy : 0.4638\n","Trained samples in this epoch : 3072\n","Step : 47/1698.\n","Loss : 1.4407.\n","Accuracy : 0.4652\n","Trained samples in this epoch : 3136\n","Step : 48/1698.\n","Loss : 1.4428.\n","Accuracy : 0.4643\n","Trained samples in this epoch : 3200\n","Step : 49/1698.\n","Loss : 1.4431.\n","Accuracy : 0.4656\n","Trained samples in this epoch : 3264\n","Step : 50/1698.\n","Loss : 1.4429.\n","Accuracy : 0.4645\n","Trained samples in this epoch : 3328\n","Step : 51/1698.\n","Loss : 1.4428.\n","Accuracy : 0.4645\n","Trained samples in this epoch : 3392\n","Step : 52/1698.\n","Loss : 1.4426.\n","Accuracy : 0.4652\n","Trained samples in this epoch : 3456\n","Step : 53/1698.\n","Loss : 1.4412.\n","Accuracy : 0.4656\n","Trained samples in this epoch : 3520\n","Step : 54/1698.\n","Loss : 1.4459.\n","Accuracy : 0.4631\n","Trained samples in this epoch : 3584\n","Step : 55/1698.\n","Loss : 1.4467.\n","Accuracy : 0.4629\n","Trained samples in this epoch : 3648\n","Step : 56/1698.\n","Loss : 1.4460.\n","Accuracy : 0.4635\n","Trained samples in this epoch : 3712\n","Step : 57/1698.\n","Loss : 1.4492.\n","Accuracy : 0.4617\n","Trained samples in this epoch : 3776\n","Step : 58/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4611\n","Trained samples in this epoch : 3840\n","Step : 59/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4599\n","Trained samples in this epoch : 3904\n","Step : 60/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4593\n","Trained samples in this epoch : 3968\n","Step : 61/1698.\n","Loss : 1.4511.\n","Accuracy : 0.4587\n","Trained samples in this epoch : 4032\n","Step : 62/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 4096\n","Step : 63/1698.\n","Loss : 1.4485.\n","Accuracy : 0.4578\n","Trained samples in this epoch : 4160\n","Step : 64/1698.\n","Loss : 1.4467.\n","Accuracy : 0.4594\n","Trained samples in this epoch : 4224\n","Step : 65/1698.\n","Loss : 1.4453.\n","Accuracy : 0.4593\n","Trained samples in this epoch : 4288\n","Step : 66/1698.\n","Loss : 1.4440.\n","Accuracy : 0.4599\n","Trained samples in this epoch : 4352\n","Step : 67/1698.\n","Loss : 1.4419.\n","Accuracy : 0.4607\n","Trained samples in this epoch : 4416\n","Step : 68/1698.\n","Loss : 1.4440.\n","Accuracy : 0.4590\n","Trained samples in this epoch : 4480\n","Step : 69/1698.\n","Loss : 1.4465.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 4544\n","Step : 70/1698.\n","Loss : 1.4460.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 4608\n","Step : 71/1698.\n","Loss : 1.4453.\n","Accuracy : 0.4575\n","Trained samples in this epoch : 4672\n","Step : 72/1698.\n","Loss : 1.4423.\n","Accuracy : 0.4587\n","Trained samples in this epoch : 4736\n","Step : 73/1698.\n","Loss : 1.4446.\n","Accuracy : 0.4576\n","Trained samples in this epoch : 4800\n","Step : 74/1698.\n","Loss : 1.4461.\n","Accuracy : 0.4577\n","Trained samples in this epoch : 4864\n","Step : 75/1698.\n","Loss : 1.4450.\n","Accuracy : 0.4581\n","Trained samples in this epoch : 4928\n","Step : 76/1698.\n","Loss : 1.4441.\n","Accuracy : 0.4582\n","Trained samples in this epoch : 4992\n","Step : 77/1698.\n","Loss : 1.4452.\n","Accuracy : 0.4579\n","Trained samples in this epoch : 5056\n","Step : 78/1698.\n","Loss : 1.4463.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 5120\n","Step : 79/1698.\n","Loss : 1.4457.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 5184\n","Step : 80/1698.\n","Loss : 1.4459.\n","Accuracy : 0.4566\n","Trained samples in this epoch : 5248\n","Step : 81/1698.\n","Loss : 1.4456.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 5312\n","Step : 82/1698.\n","Loss : 1.4453.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 5376\n","Step : 83/1698.\n","Loss : 1.4447.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 5440\n","Step : 84/1698.\n","Loss : 1.4458.\n","Accuracy : 0.4566\n","Trained samples in this epoch : 5504\n","Step : 85/1698.\n","Loss : 1.4473.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 5568\n","Step : 86/1698.\n","Loss : 1.4494.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 5632\n","Step : 87/1698.\n","Loss : 1.4476.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 5696\n","Step : 88/1698.\n","Loss : 1.4493.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 5760\n","Step : 89/1698.\n","Loss : 1.4490.\n","Accuracy : 0.4569\n","Trained samples in this epoch : 5824\n","Step : 90/1698.\n","Loss : 1.4491.\n","Accuracy : 0.4566\n","Trained samples in this epoch : 5888\n","Step : 91/1698.\n","Loss : 1.4504.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 5952\n","Step : 92/1698.\n","Loss : 1.4498.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 6016\n","Step : 93/1698.\n","Loss : 1.4509.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 6080\n","Step : 94/1698.\n","Loss : 1.4526.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 6144\n","Step : 95/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 6208\n","Step : 96/1698.\n","Loss : 1.4519.\n","Accuracy : 0.4567\n","Trained samples in this epoch : 6272\n","Step : 97/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 6336\n","Step : 98/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 6400\n","Step : 99/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 6464\n","Step : 100/1698.\n","Loss : 1.4508.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 6528\n","Step : 101/1698.\n","Loss : 1.4495.\n","Accuracy : 0.4573\n","Trained samples in this epoch : 6592\n","Step : 102/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4565\n","Trained samples in this epoch : 6656\n","Step : 103/1698.\n","Loss : 1.4490.\n","Accuracy : 0.4567\n","Trained samples in this epoch : 6720\n","Step : 104/1698.\n","Loss : 1.4482.\n","Accuracy : 0.4568\n","Trained samples in this epoch : 6784\n","Step : 105/1698.\n","Loss : 1.4482.\n","Accuracy : 0.4574\n","Trained samples in this epoch : 6848\n","Step : 106/1698.\n","Loss : 1.4474.\n","Accuracy : 0.4577\n","Trained samples in this epoch : 6912\n","Step : 107/1698.\n","Loss : 1.4456.\n","Accuracy : 0.4580\n","Trained samples in this epoch : 6976\n","Step : 108/1698.\n","Loss : 1.4446.\n","Accuracy : 0.4586\n","Trained samples in this epoch : 7040\n","Step : 109/1698.\n","Loss : 1.4436.\n","Accuracy : 0.4589\n","Trained samples in this epoch : 7104\n","Step : 110/1698.\n","Loss : 1.4448.\n","Accuracy : 0.4589\n","Trained samples in this epoch : 7168\n","Step : 111/1698.\n","Loss : 1.4457.\n","Accuracy : 0.4590\n","Trained samples in this epoch : 7232\n","Step : 112/1698.\n","Loss : 1.4474.\n","Accuracy : 0.4589\n","Trained samples in this epoch : 7296\n","Step : 113/1698.\n","Loss : 1.4483.\n","Accuracy : 0.4581\n","Trained samples in this epoch : 7360\n","Step : 114/1698.\n","Loss : 1.4481.\n","Accuracy : 0.4583\n","Trained samples in this epoch : 7424\n","Step : 115/1698.\n","Loss : 1.4475.\n","Accuracy : 0.4578\n","Trained samples in this epoch : 7488\n","Step : 116/1698.\n","Loss : 1.4476.\n","Accuracy : 0.4581\n","Trained samples in this epoch : 7552\n","Step : 117/1698.\n","Loss : 1.4491.\n","Accuracy : 0.4578\n","Trained samples in this epoch : 7616\n","Step : 118/1698.\n","Loss : 1.4476.\n","Accuracy : 0.4581\n","Trained samples in this epoch : 7680\n","Step : 119/1698.\n","Loss : 1.4488.\n","Accuracy : 0.4576\n","Trained samples in this epoch : 7744\n","Step : 120/1698.\n","Loss : 1.4472.\n","Accuracy : 0.4569\n","Trained samples in this epoch : 7808\n","Step : 121/1698.\n","Loss : 1.4476.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 7872\n","Step : 122/1698.\n","Loss : 1.4494.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 7936\n","Step : 123/1698.\n","Loss : 1.4488.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 8000\n","Step : 124/1698.\n","Loss : 1.4488.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 8064\n","Step : 125/1698.\n","Loss : 1.4514.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 8128\n","Step : 126/1698.\n","Loss : 1.4511.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 8192\n","Step : 127/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 8256\n","Step : 128/1698.\n","Loss : 1.4508.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 8320\n","Step : 129/1698.\n","Loss : 1.4504.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 8384\n","Step : 130/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 8448\n","Step : 131/1698.\n","Loss : 1.4504.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 8512\n","Step : 132/1698.\n","Loss : 1.4502.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 8576\n","Step : 133/1698.\n","Loss : 1.4509.\n","Accuracy : 0.4531\n","Trained samples in this epoch : 8640\n","Step : 134/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4528\n","Trained samples in this epoch : 8704\n","Step : 135/1698.\n","Loss : 1.4494.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 8768\n","Step : 136/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4532\n","Trained samples in this epoch : 8832\n","Step : 137/1698.\n","Loss : 1.4503.\n","Accuracy : 0.4530\n","Trained samples in this epoch : 8896\n","Step : 138/1698.\n","Loss : 1.4512.\n","Accuracy : 0.4528\n","Trained samples in this epoch : 8960\n","Step : 139/1698.\n","Loss : 1.4514.\n","Accuracy : 0.4526\n","Trained samples in this epoch : 9024\n","Step : 140/1698.\n","Loss : 1.4520.\n","Accuracy : 0.4522\n","Trained samples in this epoch : 9088\n","Step : 141/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4520\n","Trained samples in this epoch : 9152\n","Step : 142/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4517\n","Trained samples in this epoch : 9216\n","Step : 143/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4516\n","Trained samples in this epoch : 9280\n","Step : 144/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4514\n","Trained samples in this epoch : 9344\n","Step : 145/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4518\n","Trained samples in this epoch : 9408\n","Step : 146/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4526\n","Trained samples in this epoch : 9472\n","Step : 147/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4524\n","Trained samples in this epoch : 9536\n","Step : 148/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4526\n","Trained samples in this epoch : 9600\n","Step : 149/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4523\n","Trained samples in this epoch : 9664\n","Step : 150/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4523\n","Trained samples in this epoch : 9728\n","Step : 151/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4519\n","Trained samples in this epoch : 9792\n","Step : 152/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4526\n","Trained samples in this epoch : 9856\n","Step : 153/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4529\n","Trained samples in this epoch : 9920\n","Step : 154/1698.\n","Loss : 1.4508.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 9984\n","Step : 155/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 10048\n","Step : 156/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 10112\n","Step : 157/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4533\n","Trained samples in this epoch : 10176\n","Step : 158/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4528\n","Trained samples in this epoch : 10240\n","Step : 159/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4534\n","Trained samples in this epoch : 10304\n","Step : 160/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4531\n","Trained samples in this epoch : 10368\n","Step : 161/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 10432\n","Step : 162/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4529\n","Trained samples in this epoch : 10496\n","Step : 163/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4531\n","Trained samples in this epoch : 10560\n","Step : 164/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 10624\n","Step : 165/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 10688\n","Step : 166/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 10752\n","Step : 167/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 10816\n","Step : 168/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4532\n","Trained samples in this epoch : 10880\n","Step : 169/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4529\n","Trained samples in this epoch : 10944\n","Step : 170/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 11008\n","Step : 171/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 11072\n","Step : 172/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4533\n","Trained samples in this epoch : 11136\n","Step : 173/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4532\n","Trained samples in this epoch : 11200\n","Step : 174/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 11264\n","Step : 175/1698.\n","Loss : 1.4559.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 11328\n","Step : 176/1698.\n","Loss : 1.4556.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 11392\n","Step : 177/1698.\n","Loss : 1.4562.\n","Accuracy : 0.4533\n","Trained samples in this epoch : 11456\n","Step : 178/1698.\n","Loss : 1.4569.\n","Accuracy : 0.4530\n","Trained samples in this epoch : 11520\n","Step : 179/1698.\n","Loss : 1.4571.\n","Accuracy : 0.4533\n","Trained samples in this epoch : 11584\n","Step : 180/1698.\n","Loss : 1.4557.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 11648\n","Step : 181/1698.\n","Loss : 1.4552.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 11712\n","Step : 182/1698.\n","Loss : 1.4566.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 11776\n","Step : 183/1698.\n","Loss : 1.4574.\n","Accuracy : 0.4528\n","Trained samples in this epoch : 11840\n","Step : 184/1698.\n","Loss : 1.4573.\n","Accuracy : 0.4530\n","Trained samples in this epoch : 11904\n","Step : 185/1698.\n","Loss : 1.4575.\n","Accuracy : 0.4528\n","Trained samples in this epoch : 11968\n","Step : 186/1698.\n","Loss : 1.4567.\n","Accuracy : 0.4534\n","Trained samples in this epoch : 12032\n","Step : 187/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 12096\n","Step : 188/1698.\n","Loss : 1.4561.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 12160\n","Step : 189/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 12224\n","Step : 190/1698.\n","Loss : 1.4562.\n","Accuracy : 0.4534\n","Trained samples in this epoch : 12288\n","Step : 191/1698.\n","Loss : 1.4556.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 12352\n","Step : 192/1698.\n","Loss : 1.4566.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 12416\n","Step : 193/1698.\n","Loss : 1.4562.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 12480\n","Step : 194/1698.\n","Loss : 1.4557.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 12544\n","Step : 195/1698.\n","Loss : 1.4567.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 12608\n","Step : 196/1698.\n","Loss : 1.4558.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 12672\n","Step : 197/1698.\n","Loss : 1.4555.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 12736\n","Step : 198/1698.\n","Loss : 1.4560.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 12800\n","Step : 199/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 12864\n","Step : 200/1698.\n","Loss : 1.4570.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 12928\n","Step : 201/1698.\n","Loss : 1.4565.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 12992\n","Step : 202/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 13056\n","Step : 203/1698.\n","Loss : 1.4554.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 13120\n","Step : 204/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 13184\n","Step : 205/1698.\n","Loss : 1.4551.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 13248\n","Step : 206/1698.\n","Loss : 1.4550.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 13312\n","Step : 207/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 13376\n","Step : 208/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4557\n","Val acc : 0.3977\n","Val Loss : 1.6627\n","Lose_time/Patience : 2/5 .\n","Trained samples in this epoch : 13440\n","Step : 209/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 13504\n","Step : 210/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 13568\n","Step : 211/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 13632\n","Step : 212/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 13696\n","Step : 213/1698.\n","Loss : 1.4522.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 13760\n","Step : 214/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 13824\n","Step : 215/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 13888\n","Step : 216/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 13952\n","Step : 217/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 14016\n","Step : 218/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 14080\n","Step : 219/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 14144\n","Step : 220/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 14208\n","Step : 221/1698.\n","Loss : 1.4527.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 14272\n","Step : 222/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 14336\n","Step : 223/1698.\n","Loss : 1.4515.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 14400\n","Step : 224/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 14464\n","Step : 225/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 14528\n","Step : 226/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 14592\n","Step : 227/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 14656\n","Step : 228/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 14720\n","Step : 229/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 14784\n","Step : 230/1698.\n","Loss : 1.4522.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 14848\n","Step : 231/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 14912\n","Step : 232/1698.\n","Loss : 1.4513.\n","Accuracy : 0.4564\n","Trained samples in this epoch : 14976\n","Step : 233/1698.\n","Loss : 1.4509.\n","Accuracy : 0.4567\n","Trained samples in this epoch : 15040\n","Step : 234/1698.\n","Loss : 1.4515.\n","Accuracy : 0.4567\n","Trained samples in this epoch : 15104\n","Step : 235/1698.\n","Loss : 1.4514.\n","Accuracy : 0.4566\n","Trained samples in this epoch : 15168\n","Step : 236/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 15232\n","Step : 237/1698.\n","Loss : 1.4502.\n","Accuracy : 0.4574\n","Trained samples in this epoch : 15296\n","Step : 238/1698.\n","Loss : 1.4500.\n","Accuracy : 0.4575\n","Trained samples in this epoch : 15360\n","Step : 239/1698.\n","Loss : 1.4514.\n","Accuracy : 0.4570\n","Trained samples in this epoch : 15424\n","Step : 240/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4570\n","Trained samples in this epoch : 15488\n","Step : 241/1698.\n","Loss : 1.4505.\n","Accuracy : 0.4573\n","Trained samples in this epoch : 15552\n","Step : 242/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 15616\n","Step : 243/1698.\n","Loss : 1.4509.\n","Accuracy : 0.4569\n","Trained samples in this epoch : 15680\n","Step : 244/1698.\n","Loss : 1.4508.\n","Accuracy : 0.4569\n","Trained samples in this epoch : 15744\n","Step : 245/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4566\n","Trained samples in this epoch : 15808\n","Step : 246/1698.\n","Loss : 1.4500.\n","Accuracy : 0.4570\n","Trained samples in this epoch : 15872\n","Step : 247/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4570\n","Trained samples in this epoch : 15936\n","Step : 248/1698.\n","Loss : 1.4502.\n","Accuracy : 0.4568\n","Trained samples in this epoch : 16000\n","Step : 249/1698.\n","Loss : 1.4502.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 16064\n","Step : 250/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 16128\n","Step : 251/1698.\n","Loss : 1.4499.\n","Accuracy : 0.4572\n","Trained samples in this epoch : 16192\n","Step : 252/1698.\n","Loss : 1.4498.\n","Accuracy : 0.4571\n","Trained samples in this epoch : 16256\n","Step : 253/1698.\n","Loss : 1.4489.\n","Accuracy : 0.4573\n","Trained samples in this epoch : 16320\n","Step : 254/1698.\n","Loss : 1.4491.\n","Accuracy : 0.4570\n","Trained samples in this epoch : 16384\n","Step : 255/1698.\n","Loss : 1.4497.\n","Accuracy : 0.4568\n","Trained samples in this epoch : 16448\n","Step : 256/1698.\n","Loss : 1.4497.\n","Accuracy : 0.4564\n","Trained samples in this epoch : 16512\n","Step : 257/1698.\n","Loss : 1.4499.\n","Accuracy : 0.4565\n","Trained samples in this epoch : 16576\n","Step : 258/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4564\n","Trained samples in this epoch : 16640\n","Step : 259/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 16704\n","Step : 260/1698.\n","Loss : 1.4509.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 16768\n","Step : 261/1698.\n","Loss : 1.4504.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 16832\n","Step : 262/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4563\n","Trained samples in this epoch : 16896\n","Step : 263/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 16960\n","Step : 264/1698.\n","Loss : 1.4501.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 17024\n","Step : 265/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 17088\n","Step : 266/1698.\n","Loss : 1.4511.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 17152\n","Step : 267/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 17216\n","Step : 268/1698.\n","Loss : 1.4499.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 17280\n","Step : 269/1698.\n","Loss : 1.4497.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 17344\n","Step : 270/1698.\n","Loss : 1.4495.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 17408\n","Step : 271/1698.\n","Loss : 1.4503.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 17472\n","Step : 272/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 17536\n","Step : 273/1698.\n","Loss : 1.4504.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 17600\n","Step : 274/1698.\n","Loss : 1.4513.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 17664\n","Step : 275/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 17728\n","Step : 276/1698.\n","Loss : 1.4505.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 17792\n","Step : 277/1698.\n","Loss : 1.4507.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 17856\n","Step : 278/1698.\n","Loss : 1.4505.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 17920\n","Step : 279/1698.\n","Loss : 1.4506.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 17984\n","Step : 280/1698.\n","Loss : 1.4512.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 18048\n","Step : 281/1698.\n","Loss : 1.4511.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 18112\n","Step : 282/1698.\n","Loss : 1.4513.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 18176\n","Step : 283/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 18240\n","Step : 284/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 18304\n","Step : 285/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 18368\n","Step : 286/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 18432\n","Step : 287/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 18496\n","Step : 288/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 18560\n","Step : 289/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 18624\n","Step : 290/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 18688\n","Step : 291/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 18752\n","Step : 292/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 18816\n","Step : 293/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 18880\n","Step : 294/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 18944\n","Step : 295/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 19008\n","Step : 296/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 19072\n","Step : 297/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 19136\n","Step : 298/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 19200\n","Step : 299/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 19264\n","Step : 300/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 19328\n","Step : 301/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 19392\n","Step : 302/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 19456\n","Step : 303/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 19520\n","Step : 304/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 19584\n","Step : 305/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 19648\n","Step : 306/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 19712\n","Step : 307/1698.\n","Loss : 1.4553.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 19776\n","Step : 308/1698.\n","Loss : 1.4552.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 19840\n","Step : 309/1698.\n","Loss : 1.4551.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 19904\n","Step : 310/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 19968\n","Step : 311/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 20032\n","Step : 312/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 20096\n","Step : 313/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 20160\n","Step : 314/1698.\n","Loss : 1.4550.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 20224\n","Step : 315/1698.\n","Loss : 1.4550.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 20288\n","Step : 316/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 20352\n","Step : 317/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 20416\n","Step : 318/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 20480\n","Step : 319/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 20544\n","Step : 320/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 20608\n","Step : 321/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 20672\n","Step : 322/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 20736\n","Step : 323/1698.\n","Loss : 1.4526.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 20800\n","Step : 324/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 20864\n","Step : 325/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 20928\n","Step : 326/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 20992\n","Step : 327/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 21056\n","Step : 328/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 21120\n","Step : 329/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 21184\n","Step : 330/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 21248\n","Step : 331/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 21312\n","Step : 332/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 21376\n","Step : 333/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 21440\n","Step : 334/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 21504\n","Step : 335/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 21568\n","Step : 336/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 21632\n","Step : 337/1698.\n","Loss : 1.4526.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 21696\n","Step : 338/1698.\n","Loss : 1.4527.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 21760\n","Step : 339/1698.\n","Loss : 1.4526.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 21824\n","Step : 340/1698.\n","Loss : 1.4522.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 21888\n","Step : 341/1698.\n","Loss : 1.4520.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 21952\n","Step : 342/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 22016\n","Step : 343/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 22080\n","Step : 344/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 22144\n","Step : 345/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 22208\n","Step : 346/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 22272\n","Step : 347/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 22336\n","Step : 348/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 22400\n","Step : 349/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 22464\n","Step : 350/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 22528\n","Step : 351/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 22592\n","Step : 352/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 22656\n","Step : 353/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 22720\n","Step : 354/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 22784\n","Step : 355/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 22848\n","Step : 356/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 22912\n","Step : 357/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 22976\n","Step : 358/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 23040\n","Step : 359/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23104\n","Step : 360/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 23168\n","Step : 361/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 23232\n","Step : 362/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 23296\n","Step : 363/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23360\n","Step : 364/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 23424\n","Step : 365/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 23488\n","Step : 366/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 23552\n","Step : 367/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 23616\n","Step : 368/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23680\n","Step : 369/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23744\n","Step : 370/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23808\n","Step : 371/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 23872\n","Step : 372/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 23936\n","Step : 373/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 24000\n","Step : 374/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 24064\n","Step : 375/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 24128\n","Step : 376/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 24192\n","Step : 377/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 24256\n","Step : 378/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 24320\n","Step : 379/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 24384\n","Step : 380/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 24448\n","Step : 381/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 24512\n","Step : 382/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 24576\n","Step : 383/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 24640\n","Step : 384/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 24704\n","Step : 385/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 24768\n","Step : 386/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 24832\n","Step : 387/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 24896\n","Step : 388/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 24960\n","Step : 389/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 25024\n","Step : 390/1698.\n","Loss : 1.4525.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 25088\n","Step : 391/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 25152\n","Step : 392/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 25216\n","Step : 393/1698.\n","Loss : 1.4517.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 25280\n","Step : 394/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 25344\n","Step : 395/1698.\n","Loss : 1.4520.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 25408\n","Step : 396/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 25472\n","Step : 397/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 25536\n","Step : 398/1698.\n","Loss : 1.4511.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 25600\n","Step : 399/1698.\n","Loss : 1.4512.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 25664\n","Step : 400/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 25728\n","Step : 401/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 25792\n","Step : 402/1698.\n","Loss : 1.4519.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 25856\n","Step : 403/1698.\n","Loss : 1.4522.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 25920\n","Step : 404/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 25984\n","Step : 405/1698.\n","Loss : 1.4517.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 26048\n","Step : 406/1698.\n","Loss : 1.4515.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 26112\n","Step : 407/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 26176\n","Step : 408/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4555\n","Val acc : 0.3992\n","Val Loss : 1.6605\n","Lose_time/Patience : 3/5 .\n","Trained samples in this epoch : 26240\n","Step : 409/1698.\n","Loss : 1.4516.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 26304\n","Step : 410/1698.\n","Loss : 1.4515.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 26368\n","Step : 411/1698.\n","Loss : 1.4519.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 26432\n","Step : 412/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 26496\n","Step : 413/1698.\n","Loss : 1.4524.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 26560\n","Step : 414/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 26624\n","Step : 415/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 26688\n","Step : 416/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 26752\n","Step : 417/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 26816\n","Step : 418/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 26880\n","Step : 419/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 26944\n","Step : 420/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 27008\n","Step : 421/1698.\n","Loss : 1.4526.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 27072\n","Step : 422/1698.\n","Loss : 1.4519.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27136\n","Step : 423/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 27200\n","Step : 424/1698.\n","Loss : 1.4517.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27264\n","Step : 425/1698.\n","Loss : 1.4513.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 27328\n","Step : 426/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 27392\n","Step : 427/1698.\n","Loss : 1.4514.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 27456\n","Step : 428/1698.\n","Loss : 1.4510.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 27520\n","Step : 429/1698.\n","Loss : 1.4513.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27584\n","Step : 430/1698.\n","Loss : 1.4517.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 27648\n","Step : 431/1698.\n","Loss : 1.4518.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27712\n","Step : 432/1698.\n","Loss : 1.4520.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 27776\n","Step : 433/1698.\n","Loss : 1.4521.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27840\n","Step : 434/1698.\n","Loss : 1.4523.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 27904\n","Step : 435/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 27968\n","Step : 436/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 28032\n","Step : 437/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 28096\n","Step : 438/1698.\n","Loss : 1.4529.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 28160\n","Step : 439/1698.\n","Loss : 1.4528.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 28224\n","Step : 440/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 28288\n","Step : 441/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 28352\n","Step : 442/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 28416\n","Step : 443/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 28480\n","Step : 444/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 28544\n","Step : 445/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 28608\n","Step : 446/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 28672\n","Step : 447/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 28736\n","Step : 448/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 28800\n","Step : 449/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 28864\n","Step : 450/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 28928\n","Step : 451/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 28992\n","Step : 452/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 29056\n","Step : 453/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 29120\n","Step : 454/1698.\n","Loss : 1.4546.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 29184\n","Step : 455/1698.\n","Loss : 1.4550.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 29248\n","Step : 456/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 29312\n","Step : 457/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 29376\n","Step : 458/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4558\n","Trained samples in this epoch : 29440\n","Step : 459/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 29504\n","Step : 460/1698.\n","Loss : 1.4531.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 29568\n","Step : 461/1698.\n","Loss : 1.4534.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 29632\n","Step : 462/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 29696\n","Step : 463/1698.\n","Loss : 1.4530.\n","Accuracy : 0.4562\n","Trained samples in this epoch : 29760\n","Step : 464/1698.\n","Loss : 1.4535.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 29824\n","Step : 465/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4559\n","Trained samples in this epoch : 29888\n","Step : 466/1698.\n","Loss : 1.4533.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 29952\n","Step : 467/1698.\n","Loss : 1.4532.\n","Accuracy : 0.4561\n","Trained samples in this epoch : 30016\n","Step : 468/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 30080\n","Step : 469/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4560\n","Trained samples in this epoch : 30144\n","Step : 470/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4557\n","Trained samples in this epoch : 30208\n","Step : 471/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4556\n","Trained samples in this epoch : 30272\n","Step : 472/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 30336\n","Step : 473/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 30400\n","Step : 474/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 30464\n","Step : 475/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 30528\n","Step : 476/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 30592\n","Step : 477/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 30656\n","Step : 478/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 30720\n","Step : 479/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 30784\n","Step : 480/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 30848\n","Step : 481/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 30912\n","Step : 482/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4555\n","Trained samples in this epoch : 30976\n","Step : 483/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 31040\n","Step : 484/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4554\n","Trained samples in this epoch : 31104\n","Step : 485/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 31168\n","Step : 486/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 31232\n","Step : 487/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 31296\n","Step : 488/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 31360\n","Step : 489/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 31424\n","Step : 490/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 31488\n","Step : 491/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 31552\n","Step : 492/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 31616\n","Step : 493/1698.\n","Loss : 1.4548.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 31680\n","Step : 494/1698.\n","Loss : 1.4549.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 31744\n","Step : 495/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 31808\n","Step : 496/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 31872\n","Step : 497/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 31936\n","Step : 498/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 32000\n","Step : 499/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 32064\n","Step : 500/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 32128\n","Step : 501/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 32192\n","Step : 502/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 32256\n","Step : 503/1698.\n","Loss : 1.4543.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 32320\n","Step : 504/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 32384\n","Step : 505/1698.\n","Loss : 1.4545.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 32448\n","Step : 506/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 32512\n","Step : 507/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 32576\n","Step : 508/1698.\n","Loss : 1.4539.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 32640\n","Step : 509/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 32704\n","Step : 510/1698.\n","Loss : 1.4541.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 32768\n","Step : 511/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 32832\n","Step : 512/1698.\n","Loss : 1.4542.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 32896\n","Step : 513/1698.\n","Loss : 1.4540.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 32960\n","Step : 514/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 33024\n","Step : 515/1698.\n","Loss : 1.4536.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 33088\n","Step : 516/1698.\n","Loss : 1.4538.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 33152\n","Step : 517/1698.\n","Loss : 1.4537.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 33216\n","Step : 518/1698.\n","Loss : 1.4544.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 33280\n","Step : 519/1698.\n","Loss : 1.4547.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 33344\n","Step : 520/1698.\n","Loss : 1.4550.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 33408\n","Step : 521/1698.\n","Loss : 1.4553.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 33472\n","Step : 522/1698.\n","Loss : 1.4554.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 33536\n","Step : 523/1698.\n","Loss : 1.4554.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 33600\n","Step : 524/1698.\n","Loss : 1.4559.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 33664\n","Step : 525/1698.\n","Loss : 1.4561.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 33728\n","Step : 526/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 33792\n","Step : 527/1698.\n","Loss : 1.4561.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 33856\n","Step : 528/1698.\n","Loss : 1.4562.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 33920\n","Step : 529/1698.\n","Loss : 1.4563.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 33984\n","Step : 530/1698.\n","Loss : 1.4564.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 34048\n","Step : 531/1698.\n","Loss : 1.4565.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 34112\n","Step : 532/1698.\n","Loss : 1.4567.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 34176\n","Step : 533/1698.\n","Loss : 1.4569.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 34240\n","Step : 534/1698.\n","Loss : 1.4570.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 34304\n","Step : 535/1698.\n","Loss : 1.4568.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 34368\n","Step : 536/1698.\n","Loss : 1.4566.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 34432\n","Step : 537/1698.\n","Loss : 1.4575.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 34496\n","Step : 538/1698.\n","Loss : 1.4584.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 34560\n","Step : 539/1698.\n","Loss : 1.4585.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 34624\n","Step : 540/1698.\n","Loss : 1.4585.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 34688\n","Step : 541/1698.\n","Loss : 1.4585.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 34752\n","Step : 542/1698.\n","Loss : 1.4590.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 34816\n","Step : 543/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4534\n","Trained samples in this epoch : 34880\n","Step : 544/1698.\n","Loss : 1.4590.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 34944\n","Step : 545/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 35008\n","Step : 546/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 35072\n","Step : 547/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 35136\n","Step : 548/1698.\n","Loss : 1.4593.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 35200\n","Step : 549/1698.\n","Loss : 1.4594.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 35264\n","Step : 550/1698.\n","Loss : 1.4594.\n","Accuracy : 0.4535\n","Trained samples in this epoch : 35328\n","Step : 551/1698.\n","Loss : 1.4593.\n","Accuracy : 0.4536\n","Trained samples in this epoch : 35392\n","Step : 552/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 35456\n","Step : 553/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 35520\n","Step : 554/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 35584\n","Step : 555/1698.\n","Loss : 1.4594.\n","Accuracy : 0.4538\n","Trained samples in this epoch : 35648\n","Step : 556/1698.\n","Loss : 1.4594.\n","Accuracy : 0.4537\n","Trained samples in this epoch : 35712\n","Step : 557/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4540\n","Trained samples in this epoch : 35776\n","Step : 558/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 35840\n","Step : 559/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 35904\n","Step : 560/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4539\n","Trained samples in this epoch : 35968\n","Step : 561/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 36032\n","Step : 562/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 36096\n","Step : 563/1698.\n","Loss : 1.4590.\n","Accuracy : 0.4541\n","Trained samples in this epoch : 36160\n","Step : 564/1698.\n","Loss : 1.4587.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 36224\n","Step : 565/1698.\n","Loss : 1.4585.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 36288\n","Step : 566/1698.\n","Loss : 1.4584.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 36352\n","Step : 567/1698.\n","Loss : 1.4581.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 36416\n","Step : 568/1698.\n","Loss : 1.4584.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 36480\n","Step : 569/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 36544\n","Step : 570/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 36608\n","Step : 571/1698.\n","Loss : 1.4583.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 36672\n","Step : 572/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 36736\n","Step : 573/1698.\n","Loss : 1.4584.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 36800\n","Step : 574/1698.\n","Loss : 1.4583.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 36864\n","Step : 575/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 36928\n","Step : 576/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 36992\n","Step : 577/1698.\n","Loss : 1.4577.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 37056\n","Step : 578/1698.\n","Loss : 1.4580.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 37120\n","Step : 579/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 37184\n","Step : 580/1698.\n","Loss : 1.4581.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 37248\n","Step : 581/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 37312\n","Step : 582/1698.\n","Loss : 1.4580.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 37376\n","Step : 583/1698.\n","Loss : 1.4576.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 37440\n","Step : 584/1698.\n","Loss : 1.4578.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 37504\n","Step : 585/1698.\n","Loss : 1.4577.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 37568\n","Step : 586/1698.\n","Loss : 1.4574.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 37632\n","Step : 587/1698.\n","Loss : 1.4571.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 37696\n","Step : 588/1698.\n","Loss : 1.4575.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 37760\n","Step : 589/1698.\n","Loss : 1.4579.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 37824\n","Step : 590/1698.\n","Loss : 1.4582.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 37888\n","Step : 591/1698.\n","Loss : 1.4585.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 37952\n","Step : 592/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 38016\n","Step : 593/1698.\n","Loss : 1.4586.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 38080\n","Step : 594/1698.\n","Loss : 1.4589.\n","Accuracy : 0.4542\n","Trained samples in this epoch : 38144\n","Step : 595/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 38208\n","Step : 596/1698.\n","Loss : 1.4587.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38272\n","Step : 597/1698.\n","Loss : 1.4589.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38336\n","Step : 598/1698.\n","Loss : 1.4589.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 38400\n","Step : 599/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 38464\n","Step : 600/1698.\n","Loss : 1.4589.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 38528\n","Step : 601/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38592\n","Step : 602/1698.\n","Loss : 1.4587.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38656\n","Step : 603/1698.\n","Loss : 1.4588.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38720\n","Step : 604/1698.\n","Loss : 1.4589.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38784\n","Step : 605/1698.\n","Loss : 1.4587.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 38848\n","Step : 606/1698.\n","Loss : 1.4587.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 38912\n","Step : 607/1698.\n","Loss : 1.4590.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 38976\n","Step : 608/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4548\n","Val acc : 0.3972\n","Val Loss : 1.6582\n","Lose_time/Patience : 4/5 .\n","Trained samples in this epoch : 39040\n","Step : 609/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39104\n","Step : 610/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39168\n","Step : 611/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 39232\n","Step : 612/1698.\n","Loss : 1.4594.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39296\n","Step : 613/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39360\n","Step : 614/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39424\n","Step : 615/1698.\n","Loss : 1.4595.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39488\n","Step : 616/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39552\n","Step : 617/1698.\n","Loss : 1.4595.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39616\n","Step : 618/1698.\n","Loss : 1.4595.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39680\n","Step : 619/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 39744\n","Step : 620/1698.\n","Loss : 1.4592.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39808\n","Step : 621/1698.\n","Loss : 1.4591.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 39872\n","Step : 622/1698.\n","Loss : 1.4598.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 39936\n","Step : 623/1698.\n","Loss : 1.4598.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 40000\n","Step : 624/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 40064\n","Step : 625/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 40128\n","Step : 626/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 40192\n","Step : 627/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 40256\n","Step : 628/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 40320\n","Step : 629/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 40384\n","Step : 630/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 40448\n","Step : 631/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 40512\n","Step : 632/1698.\n","Loss : 1.4598.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 40576\n","Step : 633/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 40640\n","Step : 634/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 40704\n","Step : 635/1698.\n","Loss : 1.4598.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 40768\n","Step : 636/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 40832\n","Step : 637/1698.\n","Loss : 1.4602.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 40896\n","Step : 638/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 40960\n","Step : 639/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 41024\n","Step : 640/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 41088\n","Step : 641/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 41152\n","Step : 642/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 41216\n","Step : 643/1698.\n","Loss : 1.4602.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41280\n","Step : 644/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 41344\n","Step : 645/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41408\n","Step : 646/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41472\n","Step : 647/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41536\n","Step : 648/1698.\n","Loss : 1.4602.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 41600\n","Step : 649/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 41664\n","Step : 650/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41728\n","Step : 651/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 41792\n","Step : 652/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41856\n","Step : 653/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 41920\n","Step : 654/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 41984\n","Step : 655/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 42048\n","Step : 656/1698.\n","Loss : 1.4602.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 42112\n","Step : 657/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 42176\n","Step : 658/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 42240\n","Step : 659/1698.\n","Loss : 1.4598.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 42304\n","Step : 660/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 42368\n","Step : 661/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 42432\n","Step : 662/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 42496\n","Step : 663/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 42560\n","Step : 664/1698.\n","Loss : 1.4595.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 42624\n","Step : 665/1698.\n","Loss : 1.4595.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 42688\n","Step : 666/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 42752\n","Step : 667/1698.\n","Loss : 1.4596.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 42816\n","Step : 668/1698.\n","Loss : 1.4597.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 42880\n","Step : 669/1698.\n","Loss : 1.4599.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 42944\n","Step : 670/1698.\n","Loss : 1.4600.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43008\n","Step : 671/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43072\n","Step : 672/1698.\n","Loss : 1.4602.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43136\n","Step : 673/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 43200\n","Step : 674/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 43264\n","Step : 675/1698.\n","Loss : 1.4613.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 43328\n","Step : 676/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43392\n","Step : 677/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 43456\n","Step : 678/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43520\n","Step : 679/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 43584\n","Step : 680/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 43648\n","Step : 681/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 43712\n","Step : 682/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 43776\n","Step : 683/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 43840\n","Step : 684/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 43904\n","Step : 685/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 43968\n","Step : 686/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44032\n","Step : 687/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44096\n","Step : 688/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44160\n","Step : 689/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 44224\n","Step : 690/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44288\n","Step : 691/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 44352\n","Step : 692/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44416\n","Step : 693/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 44480\n","Step : 694/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44544\n","Step : 695/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44608\n","Step : 696/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44672\n","Step : 697/1698.\n","Loss : 1.4603.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 44736\n","Step : 698/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44800\n","Step : 699/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 44864\n","Step : 700/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4552\n","Trained samples in this epoch : 44928\n","Step : 701/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 44992\n","Step : 702/1698.\n","Loss : 1.4601.\n","Accuracy : 0.4553\n","Trained samples in this epoch : 45056\n","Step : 703/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 45120\n","Step : 704/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 45184\n","Step : 705/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 45248\n","Step : 706/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 45312\n","Step : 707/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 45376\n","Step : 708/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 45440\n","Step : 709/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 45504\n","Step : 710/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 45568\n","Step : 711/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 45632\n","Step : 712/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 45696\n","Step : 713/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 45760\n","Step : 714/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 45824\n","Step : 715/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 45888\n","Step : 716/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 45952\n","Step : 717/1698.\n","Loss : 1.4613.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 46016\n","Step : 718/1698.\n","Loss : 1.4613.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 46080\n","Step : 719/1698.\n","Loss : 1.4616.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 46144\n","Step : 720/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46208\n","Step : 721/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 46272\n","Step : 722/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 46336\n","Step : 723/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46400\n","Step : 724/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46464\n","Step : 725/1698.\n","Loss : 1.4618.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46528\n","Step : 726/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 46592\n","Step : 727/1698.\n","Loss : 1.4616.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 46656\n","Step : 728/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46720\n","Step : 729/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 46784\n","Step : 730/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 46848\n","Step : 731/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 46912\n","Step : 732/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 46976\n","Step : 733/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47040\n","Step : 734/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47104\n","Step : 735/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 47168\n","Step : 736/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47232\n","Step : 737/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47296\n","Step : 738/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 47360\n","Step : 739/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 47424\n","Step : 740/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 47488\n","Step : 741/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 47552\n","Step : 742/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 47616\n","Step : 743/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 47680\n","Step : 744/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 47744\n","Step : 745/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 47808\n","Step : 746/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47872\n","Step : 747/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 47936\n","Step : 748/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 48000\n","Step : 749/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48064\n","Step : 750/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 48128\n","Step : 751/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48192\n","Step : 752/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48256\n","Step : 753/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48320\n","Step : 754/1698.\n","Loss : 1.4613.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48384\n","Step : 755/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48448\n","Step : 756/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48512\n","Step : 757/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48576\n","Step : 758/1698.\n","Loss : 1.4613.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 48640\n","Step : 759/1698.\n","Loss : 1.4612.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 48704\n","Step : 760/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48768\n","Step : 761/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 48832\n","Step : 762/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48896\n","Step : 763/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 48960\n","Step : 764/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 49024\n","Step : 765/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 49088\n","Step : 766/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 49152\n","Step : 767/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 49216\n","Step : 768/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 49280\n","Step : 769/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 49344\n","Step : 770/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 49408\n","Step : 771/1698.\n","Loss : 1.4604.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 49472\n","Step : 772/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 49536\n","Step : 773/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 49600\n","Step : 774/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 49664\n","Step : 775/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 49728\n","Step : 776/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 49792\n","Step : 777/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 49856\n","Step : 778/1698.\n","Loss : 1.4618.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 49920\n","Step : 779/1698.\n","Loss : 1.4618.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 49984\n","Step : 780/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50048\n","Step : 781/1698.\n","Loss : 1.4616.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50112\n","Step : 782/1698.\n","Loss : 1.4614.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 50176\n","Step : 783/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50240\n","Step : 784/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50304\n","Step : 785/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50368\n","Step : 786/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50432\n","Step : 787/1698.\n","Loss : 1.4619.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 50496\n","Step : 788/1698.\n","Loss : 1.4619.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 50560\n","Step : 789/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4544\n","Trained samples in this epoch : 50624\n","Step : 790/1698.\n","Loss : 1.4617.\n","Accuracy : 0.4543\n","Trained samples in this epoch : 50688\n","Step : 791/1698.\n","Loss : 1.4615.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 50752\n","Step : 792/1698.\n","Loss : 1.4611.\n","Accuracy : 0.4545\n","Trained samples in this epoch : 50816\n","Step : 793/1698.\n","Loss : 1.4610.\n","Accuracy : 0.4546\n","Trained samples in this epoch : 50880\n","Step : 794/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 50944\n","Step : 795/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 51008\n","Step : 796/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 51072\n","Step : 797/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4547\n","Trained samples in this epoch : 51136\n","Step : 798/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 51200\n","Step : 799/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 51264\n","Step : 800/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 51328\n","Step : 801/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4548\n","Trained samples in this epoch : 51392\n","Step : 802/1698.\n","Loss : 1.4609.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 51456\n","Step : 803/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4549\n","Trained samples in this epoch : 51520\n","Step : 804/1698.\n","Loss : 1.4606.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 51584\n","Step : 805/1698.\n","Loss : 1.4605.\n","Accuracy : 0.4551\n","Trained samples in this epoch : 51648\n","Step : 806/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 51712\n","Step : 807/1698.\n","Loss : 1.4608.\n","Accuracy : 0.4550\n","Trained samples in this epoch : 51776\n","Step : 808/1698.\n","Loss : 1.4607.\n","Accuracy : 0.4551\n","Val acc : 0.4057\n","Val Loss : 1.6373\n","Lose_time/Patience : 5/5 .\n","Stop training.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bKv3TTdgjWy","colab_type":"code","colab":{}},"source":["2020-06-12 22:16:24.473561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Reading line 100000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 200000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 300000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 400000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 500000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 600000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 700000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 800000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 900000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1000000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1100000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1200000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1300000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1400000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1500000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1600000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1700000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1800000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 1900000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 2000000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 2100000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 2200000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Reading line 2300000 in /content/drive/My Drive/192/Thesis/data/NE_data/processedData/NE_train.100000.id.txt\n","Document average length: 453.\n","Document midden length: 424.\n","Question average length: 29.\n","Question midden length: 25.\n","Document average length: 431.\n","Document midden length: 410.\n","Question average length: 26.\n","Question midden length: 25.\n","Document average length: 443.\n","Document midden length: 416.\n","Question average length: 28.\n","Question midden length: 25.\n","Embeddings: 52785 x 200\n","Loading embedding file: /content/drive/My Drive/192/Thesis/embeddings/glove.6B.200d.txt\n","Pre-trained: 36250 (68.67%)\n","2020-06-12 22:17:02.838440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-12 22:17:02.888947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:02.889866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2020-06-12 22:17:02.889912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-12 22:17:03.373977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-12 22:17:03.500018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-12 22:17:03.523815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-12 22:17:03.793984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-12 22:17:03.816168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-12 22:17:04.366913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-12 22:17:04.367083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.368185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.369084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-06-12 22:17:04.401479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n","2020-06-12 22:17:04.401828: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1614d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-12 22:17:04.401864: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-12 22:17:04.552493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.553540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1614f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-12 22:17:04.553579: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-12 22:17:04.554915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.555829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2020-06-12 22:17:04.555874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-12 22:17:04.555924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-12 22:17:04.555947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-12 22:17:04.555969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-12 22:17:04.555991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-12 22:17:04.556012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-12 22:17:04.556034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-12 22:17:04.556116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.557017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:04.557853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-06-12 22:17:04.562595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-12 22:17:10.994460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-12 22:17:10.994512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n","2020-06-12 22:17:10.994528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n","2020-06-12 22:17:11.000588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.001477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.002266: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-12 22:17:11.002324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Embedding matrix shape:52785 x 200\n","2020-06-12 22:17:11.192457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.193370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2020-06-12 22:17:11.193428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-12 22:17:11.193455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-12 22:17:11.193477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-12 22:17:11.193497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-12 22:17:11.193520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-12 22:17:11.193540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-12 22:17:11.193560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-12 22:17:11.193662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.194509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.195272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-06-12 22:17:11.195355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-12 22:17:11.195365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n","2020-06-12 22:17:11.195377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n","2020-06-12 22:17:11.195478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.196371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-12 22:17:11.197271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"azPrMmedy1Lc","colab_type":"code","colab":{}},"source":["tt = \"true\"\n","\n","t = bool(tt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySg4mXYry5bq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592004445678,"user_tz":-180,"elapsed":496,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"1aec6472-76c5-41ab-baec-288aa7a3689b"},"source":["t, tt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, 'False')"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"4q89GZjAy6Ma","colab_type":"code","colab":{}},"source":["import json\n","t = json.loads(tt.lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sA4qys43gOr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592004605052,"user_tz":-180,"elapsed":640,"user":{"displayName":"Fahd Al Sahali","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkaYWUC0MfH4_gpXliKkJLZ3dwsiHm7Ok3qIYajw=s64","userId":"14743331008726039331"}},"outputId":"b6486de9-ebdf-4919-d70a-1558208613dc"},"source":["t, type(t)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, bool)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"yUJGPEKA3gzy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}